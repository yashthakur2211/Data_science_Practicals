{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e382549-3a23-4d7d-8887-4b5381a2932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\yash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.28-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.9 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/41.9 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.9/41.9 kB 674.1 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\yash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2024.4.28-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 194.6/268.5 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.5/268.5 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2024.4.28 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2270881-8e84-4615-bf36-129ccc2663bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Yash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d20592-0647-4774-a5d8-2497334dd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=' CSK won the IPLT Trophy 5 times . Mumbai also won the trophy 5 times . They have best rivalary among them'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417fed66-3560-4759-94e0-c047904a6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' CSK won the IPLT Trophy 5 times .', 'Mumbai also won the trophy 5 times .', 'They have best rivalary among them']\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION\n",
    "\n",
    "tokens_sent = nltk.sent_tokenize(text)\n",
    "print(tokens_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9f5af6-1f22-4715-9062-967fdd7dc374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSK', 'won', 'the', 'IPLT', 'Trophy', '5', 'times', '.', 'Mumbai', 'also', 'won', 'the', 'trophy', '5', 'times', '.', 'They', 'have', 'best', 'rivalary', 'among', 'them']\n"
     ]
    }
   ],
   "source": [
    "tokens_word = nltk.word_tokenize(text)\n",
    "print(tokens_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb6000b-5900-47d8-af53-e08540a69e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# STOPWORDS\n",
    "\n",
    "stop_word = stopwords.words('english')\n",
    "print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857850c9-b846-4f5f-8555-a063c68e6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSK IPLT Trophy 5 times . Mumbai also trophy 5 times . best rivalary among\n"
     ]
    }
   ],
   "source": [
    "words = [word for word in text.split() if word.lower() not in stop_word]\n",
    "new_text = \" \".join(words)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bc787d-f433-4df4-aac9-2fb84525f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMMITIZAR \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d527fc-aad9-4a04-958b-0b55d9403e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSK won the IPLT Trophy 5 time . Mumbai also won the trophy 5 time . They have best rivalary among them\n"
     ]
    }
   ],
   "source": [
    "stem = ['CSK', 'won', 'the', 'IPLT', 'Trophy', '5', 'times', '.', 'Mumbai', 'also', 'won', 'the', 'trophy', '5', 'times', '.', 'They', 'have', 'best', 'rivalary', 'among', 'them']\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in stem])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f36baf9-c8ed-4310-bd56-6432fa63cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSK', 'won', 'the', 'IPLT', 'Trophy', '5', 'time', '.', 'Mumbai', 'also', 'won', 'the', 'trophy', '5', 'time', '.', 'They', 'have', 'best', 'rivalary', 'among', 'them']\n"
     ]
    }
   ],
   "source": [
    "leme=[]\n",
    "for i in stem:\n",
    "  lemetized_word=lemmatizer.lemmatize(i)\n",
    "  leme.append(lemetized_word)\n",
    "print(leme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84d2729c-d692-4b93-97d1-2b7582d93d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech:  [('CSK', 'NNP'), ('won', 'VBD'), ('the', 'DT'), ('IPLT', 'NNP'), ('Trophy', 'NNP'), ('5', 'CD'), ('times', 'NNS'), ('.', '.'), ('Mumbai', 'NNP'), ('also', 'RB'), ('won', 'VBD'), ('the', 'DT'), ('trophy', 'NN'), ('5', 'CD'), ('times', 'NNS'), ('.', '.'), ('They', 'PRP'), ('have', 'VBP'), ('best', 'JJS'), ('rivalary', 'JJ'), ('among', 'IN'), ('them', 'PRP')]\n"
     ]
    }
   ],
   "source": [
    "# PART OF SPEECH \n",
    "\n",
    "print(\"Parts of Speech: \",nltk.pos_tag(tokens_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17870fc0-357f-460d-ba0a-9fa4db000ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer = TfidfVectorizer()\n",
    "tfid_matrix =tfid_vectorizer.fit_transform([filtered_text ,stemmed_text,lemmatized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b826ff-39b9-444b-a1c0-9befbfbd8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = tfid_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02359b-7675-4028-8141-e55c11a92cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tfid_matrix.toarray(),columns=feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985e2f3-5682-4017-9671-ed281c6f24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTF-IDF Representation:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
